{
 "cells": [
  {
   "cell_type": "code",
   "id": "f39abe0139f3ea29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T14:16:59.482677Z",
     "start_time": "2025-08-17T14:16:59.480459Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T14:17:02.342276Z",
     "start_time": "2025-08-17T14:16:59.603755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "from matplotlib import pyplot as plt\n",
    "import logging\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "import os\n",
    "os.environ.pop(\"MPLDEBUG\", None)\n",
    "import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from model import TripleStreamsVAE\n",
    "from data import get_triplestream_dataset\n",
    "from helpers.control_feature_utils import run_inference_and_extract_features, run_inference, extract_control_features\n",
    "\n"
   ],
   "id": "33c7270ea97a63ec",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import fluidsynth. AUDIO rendering will not work.\n",
      "Holoviews not installed. Please install holoviews to be able to generate heatmaps.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "f39ad373db3dd68c",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "### Note: First run, it will take a while to load the dataset, but it will be cached for future runs."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T14:17:08.645882Z",
     "start_time": "2025-08-17T14:17:02.345493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = yaml.safe_load(open('../helpers/configs/TripleStreams_0.5.yaml', 'r'))\n",
    "config['dataset_root_path'] = os.path.join(\"../\", config['dataset_root_path'])\n",
    "\n",
    "is_testing = False\n",
    "\n",
    "dataset = get_triplestream_dataset(\n",
    "        config=config,\n",
    "        subset_tag=\"validation\",\n",
    "        use_cached=True,\n",
    "        downsampled_size=2000 if is_testing else None,\n",
    "        print_logs=False                                #<---  Set to True to print dataset loading logs\n",
    "    )"
   ],
   "id": "6e51f36f85b4215e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "350e2f7a9cce44bf",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "dc6f5203529a8a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T14:17:08.808416Z",
     "start_time": "2025-08-17T14:17:08.654755Z"
    }
   },
   "source": [
    "from model import load_model\n",
    "model_path = 'models/step_1542993.pth'\n",
    "model = load_model(\n",
    "    model_path=model_path,\n",
    "    model_class=TripleStreamsVAE,\n",
    "    params_dict=config,\n",
    "    is_evaluating=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "10576d572af3d2c6",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "id": "95e1e7e04853fa4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T14:17:08.964460Z",
     "start_time": "2025-08-17T14:17:08.812903Z"
    }
   },
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from data.triple_streams.triple_stream_data_utils import create_multitab_from_HVO_Sequences, compile_into_list_of_hvo_seqs\n",
    "from bokeh.io import save\n",
    "from IPython.display import HTML, display\n",
    "import torch\n",
    "import os\n",
    "\n",
    "drum_mapping = {\n",
    "    \"Input Groove\": [36],\n",
    "    \"Stream 1\": [37],\n",
    "    \"Stream 2\": [38],\n",
    "    \"Stream 3\": [39],\n",
    "}\n",
    "\n",
    "@interact_manual(\n",
    "    sample=widgets.IntSlider(min=0, max=len(dataset)-1, step=1, value=0, description='Sample'),\n",
    "    param1=widgets.IntSlider(min=0, max=32, step=1, value=0, description='Output/Input Difference'),\n",
    "    param2=widgets.IntSlider(min=0, max=9, step=1, value=0, description='Output/Input Accent Difference'),\n",
    "    param3=widgets.IntSlider(min=0, max=9, step=1, value=0, description='Density Stream 1'),\n",
    "    param4=widgets.IntSlider(min=0, max=9, step=1, value=0, description='Density Stream 2'),\n",
    "    param5=widgets.IntSlider(min=0, max=9, step=1, value=0, description='Density Stream 3')\n",
    ")\n",
    "def generate_function(sample, param1, param2, param3, param4, param5):\n",
    "    \"\"\"Generate and save plot as HTML file\"\"\"\n",
    "    print(f\"Generating with parameters: Sample={sample}, Controls=[{param1}, {param2}, {param3}, {param4}, {param5}]\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_groove = dataset.input_grooves[sample].unsqueeze(0)\n",
    "        encoding_control1_token = torch.tensor(param1, dtype=torch.long).unsqueeze(0)\n",
    "        encoding_control2_token = torch.tensor(param2, dtype=torch.long).unsqueeze(0)\n",
    "        decoding_control1_token = torch.tensor(param3, dtype=torch.long).unsqueeze(0)\n",
    "        decoding_control2_token = torch.tensor(param4, dtype=torch.long).unsqueeze(0)\n",
    "        decoding_control3_token = torch.tensor(param5, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "        hvo, latent_z = model.predict(\n",
    "            flat_hvo_groove=input_groove,\n",
    "            encoding_control1_token=encoding_control1_token,\n",
    "            encoding_control2_token=encoding_control2_token,\n",
    "            decoding_control1_token=9 - decoding_control1_token,\n",
    "            decoding_control2_token=9 - decoding_control2_token,\n",
    "            decoding_control3_token=9 - decoding_control3_token\n",
    "        )\n",
    "\n",
    "    hvo_sequence_list = compile_into_list_of_hvo_seqs(\n",
    "        input_hvos = input_groove,\n",
    "        output_hvos = hvo, \n",
    "        metadatas = [dataset.metadata[sample]]\n",
    "        \n",
    "    )\n",
    "\n",
    "    # Create the plot\n",
    "    tabs = create_multitab_from_HVO_Sequences(\n",
    "        hvos=hvo_sequence_list[0]\n",
    "    )\n",
    "\n",
    "    hvo_sequence_list[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Sample', max=395759), IntSlider(value=0, description='Ouâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b132cf679ac462eadd1280754b743f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "e999d7b3a4ea8a23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T14:17:08.974958Z",
     "start_time": "2025-08-17T14:17:08.973721Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9a4561f2-3ea6-4f73-a329-b932632db5c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T14:17:08.982091Z",
     "start_time": "2025-08-17T14:17:08.980955Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "44a7fe8a-4d2b-448f-9e4b-0a9482597611",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T14:17:08.987959Z",
     "start_time": "2025-08-17T14:17:08.986924Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f8858362-fa6e-48de-8429-b490f2339bf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T14:17:08.992776Z",
     "start_time": "2025-08-17T14:17:08.991877Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9233c1ea-998e-49c8-8177-bf7fba182d38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T14:17:08.998003Z",
     "start_time": "2025-08-17T14:17:08.996956Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "106cb48a-ee23-4f42-ba54-1f7a0aaf807a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T14:17:09.002887Z",
     "start_time": "2025-08-17T14:17:09.001976Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e3e48bfe-8dee-4324-927a-30a2fed8892b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T14:17:09.007969Z",
     "start_time": "2025-08-17T14:17:09.006883Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce3d92c0-697a-4418-98f1-875d581898a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T14:17:09.012842Z",
     "start_time": "2025-08-17T14:17:09.011779Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TripleStreams)",
   "language": "python",
   "name": "triplestreams"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
